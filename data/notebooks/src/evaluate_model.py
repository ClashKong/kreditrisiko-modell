import pandas as pd
import joblib
import os
import logging
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Logging einrichten
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Dateipfade
DATA_PATH = os.path.join("data", "kreditrisiko.csv")
MODEL_PATH = os.path.join("data", "notebooks", "src", "webapp", "best_model.pkl")
SCALER_PATH = os.path.join("data", "notebooks", "src", "webapp", "scaler.pkl")

def load_data():
    """L√§dt die Kreditrisiko-Daten als Pandas DataFrame."""
    if not os.path.exists(DATA_PATH):
        logging.error(f"‚ùå Datei nicht gefunden: {DATA_PATH}")
        raise FileNotFoundError(f"‚ùå Datei nicht gefunden: {DATA_PATH}")
    
    logging.info("üì• Daten werden geladen...")
    df = pd.read_csv(DATA_PATH)
    logging.info("‚úÖ Daten erfolgreich geladen!")
    return df

def load_model():
    """L√§dt das trainierte Modell und den Scaler."""
    if not os.path.exists(MODEL_PATH) or not os.path.exists(SCALER_PATH):
        logging.error("‚ùå Modell oder Scaler nicht gefunden!")
        raise FileNotFoundError("‚ùå Modell oder Scaler nicht gefunden!")
    
    logging.info("üì¶ Modell & Scaler werden geladen...")
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    logging.info("‚úÖ Modell & Scaler erfolgreich geladen!")
    return model, scaler

def preprocess_data(df):
    """Normalisiert die Features und trennt sie von der Zielvariable."""
    features = ['Kreditbetrag', 'Laufzeit', 'Einkommen', 'Alter', 'Kreditverlauf', 'Schuldenquote']
    target = 'Kreditw√ºrdigkeit'

    X = df[features]
    y = df[target]

    logging.info("üìä Daten werden normalisiert...")
    return X, y

def evaluate_model(model, scaler, X, y):
    """Berechnet Metriken zur Modellbewertung und gibt sie aus."""
    logging.info("üìä Modell wird evaluiert...")

    # Skalierung anwenden
    X_scaled = scaler.transform(X)
    
    # Vorhersagen
    y_pred = model.predict(X_scaled)

    # Berechnung der Metriken
    accuracy = accuracy_score(y, y_pred)
    precision = precision_score(y, y_pred)
    recall = recall_score(y, y_pred)
    f1 = f1_score(y, y_pred)
    roc_auc = roc_auc_score(y, y_pred)

    # Ergebnisse ausgeben
    logging.info("üìä Modell-Performance:")
    print("‚úÖ Genauigkeit:", round(accuracy, 4))
    print("‚úÖ Pr√§zision:", round(precision, 4))
    print("‚úÖ Recall:", round(recall, 4))
    print("‚úÖ F1-Score:", round(f1, 4))
    print("‚úÖ ROC-AUC:", round(roc_auc, 4))

    return model.feature_importances_, X.columns

def plot_feature_importance(feature_importance, feature_cols):
    """Erstellt ein Barplot zur Visualisierung der Feature-Importanz."""
    plt.figure(figsize=(10, 5))
    sns.barplot(x=feature_importance, y=feature_cols, palette="viridis")
    plt.title("Feature-Importance des Modells")
    plt.xlabel("Feature Importance")
    plt.ylabel("")
    plt.show()

def main():
    """Hauptfunktion zum Laden, Evaluieren und Visualisieren des Modells."""
    df = load_data()
    model, scaler = load_model()
    X, y = preprocess_data(df)
    
    feature_importance, feature_cols = evaluate_model(model, scaler, X, y)
    plot_feature_importance(feature_importance, feature_cols)

    logging.info("üéâ Evaluierung abgeschlossen!")

if __name__ == "__main__":
    main()
